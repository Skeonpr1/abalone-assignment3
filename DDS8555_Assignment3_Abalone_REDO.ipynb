{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fceb74ab",
   "metadata": {},
   "source": [
    "\n",
    "# DDS8555 — Assignment 3 (Abalone Regression)\n",
    "\n",
    "**Author:** Eliseo Ilarraza  \n",
    "**Models:** (1) Elastic Net → Subset OLS, (2) Principal Components Regression (PCR)  \n",
    "**Outputs:** Cross‑validated metrics, diagnostics (VIF, BP, Q–Q), and Kaggle `submission.csv` files.\n",
    "\n",
    "> **How to run (RStudio or Jupyter):**\n",
    "> 1. Put `train.csv`, `test.csv`, and `sample_submission.csv` in a `data/` folder.\n",
    "> 2. Run this notebook **top‑to‑bottom**.  \n",
    "> 3. The notebook saves: `submission_model1_enet_subset.csv` and `submission_model2_pcr.csv` into the project root.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba847e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, os, json, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_log_error, make_scorer\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"sklearn:\", __import__(\"sklearn\").__version__)\n",
    "print(\"statsmodels:\", sm.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb37798",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb97707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = \"data\"  # change if needed\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, \"train.csv\")\n",
    "TEST_PATH = os.path.join(DATA_DIR, \"test.csv\")\n",
    "SAMPLE_SUB_PATH = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "assert os.path.exists(SAMPLE_SUB_PATH), \"Place sample_submission.csv in ./data/\"\n",
    "print(\"Using:\", TRAIN_PATH, TEST_PATH, SAMPLE_SUB_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e762a1",
   "metadata": {},
   "source": [
    "## Detect target column name from sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314770fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e4e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rmsle(y_true, y_pred, clip=True):\n",
    "    y_pred = np.maximum(y_pred, 0) if clip else y_pred\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "rmsle_scorer = make_scorer(lambda yt, yp: rmsle(yt, yp), greater_is_better=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e9af35",
   "metadata": {},
   "source": [
    "## Load train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb5f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(\"Train shape:\", train.shape, \"Test shape:\", test.shape)\n",
    "display(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6193abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id_col = [c for c in train.columns if c.lower() in [\"id\",\"index\"]]\n",
    "id_col = id_col[0] if id_col else None\n",
    "\n",
    "target_col = [c for c in sample.columns if c.lower() in [\"rings\",\"target\",\"ring\",\"age\"]]\n",
    "target_col = target_col[0] if target_col else \"Rings\"\n",
    "\n",
    "y = train[target_col].values\n",
    "X = train.drop(columns=[target_col] + ([id_col] if id_col else [])).copy()\n",
    "X_test = test.drop(columns=[id_col] if id_col else []).copy()\n",
    "\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(\"Target:\", target_col, \"| #num cols:\", len(num_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6134bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1132e27a",
   "metadata": {},
   "source": [
    "## Model 1 — Elastic Net → Subset OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b40cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enet = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"enet\", ElasticNet(max_iter=5000, random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"enet__alpha\": np.logspace(-3, 1, 15),\n",
    "    \"enet__l1_ratio\": np.linspace(0.05, 0.95, 10)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(enet, param_grid, scoring=rmsle_scorer, cv=cv, n_jobs=-1)\n",
    "gs.fit(X[num_cols], y)\n",
    "best_enet = gs.best_estimator_\n",
    "print(\"Best ENet params:\", gs.best_params_, \"CV RMSLE:\", -gs.best_score_)\n",
    "\n",
    "# Identify stable nonzero features across folds via refit on full train\n",
    "best_enet.fit(X[num_cols], y)\n",
    "coefs = pd.Series(best_enet.named_steps[\"enet\"].coef_, index=num_cols)\n",
    "keep = coefs[coefs != 0].index.tolist()\n",
    "print(\"Selected features:\", keep)\n",
    "\n",
    "# Subset OLS on selected features (with scaling inside pipeline)\n",
    "X_sel = X[keep].copy()\n",
    "scaler = StandardScaler().fit(X_sel)\n",
    "X_sel_sc = scaler.transform(X_sel)\n",
    "\n",
    "ols = sm.OLS(y, sm.add_constant(X_sel_sc)).fit()\n",
    "print(ols.summary().tables[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291ca3e",
   "metadata": {},
   "source": [
    "### Diagnostics (VIF, Breusch–Pagan, Q–Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e77b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VIF\n",
    "X_vif = sm.add_constant(X_sel_sc)\n",
    "vifs = pd.Series([variance_inflation_factor(X_vif, i) for i in range(1, X_vif.shape[1])], index=keep, name=\"VIF\")\n",
    "display(vifs.to_frame())\n",
    "\n",
    "# BP test\n",
    "residuals = ols.resid\n",
    "bp_test = het_breuschpagan(residuals, ols.model.exog)\n",
    "bp_labels = [\"LM stat\", \"LM p-val\", \"F stat\", \"F p-val\"]\n",
    "bp = dict(zip(bp_labels, bp_test))\n",
    "print(\"Breusch–Pagan:\", bp)\n",
    "\n",
    "# QQ plot\n",
    "sm.qqplot(ols.get_influence().resid_studentized_internal, line='45')\n",
    "plt.title(\"Model 1: Q–Q Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0729ee4d",
   "metadata": {},
   "source": [
    "### Cross‑Validated Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cv_rmsle(model, X, y, cv):\n",
    "    scores = -cross_val_score(model, X, y, scoring=rmsle_scorer, cv=cv, n_jobs=-1)\n",
    "    return scores.mean(), scores.std()\n",
    "\n",
    "m1_mean, m1_sd = cv_rmsle(best_enet, X[num_cols], y, cv)\n",
    "print(f\"Model 1 ENet CV RMSLE = {m1_mean:.5f} ± {m1_sd:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5177a",
   "metadata": {},
   "source": [
    "### Generate Kaggle Submission — Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95dd45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_enet.fit(X[num_cols], y)\n",
    "pred1 = np.maximum(best_enet.predict(X_test[num_cols]), 0)\n",
    "\n",
    "sub1 = sample.copy()\n",
    "sub_target = sub1.columns[1] if sub1.shape[1] == 2 else [c for c in sub1.columns if c != sub1.columns[0]][0]\n",
    "sub1[sub_target] = pred1\n",
    "sub1_path = \"submission_model1_enet_subset.csv\"\n",
    "sub1.to_csv(sub1_path, index=False)\n",
    "print(\"Saved:\", sub1_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4498d331",
   "metadata": {},
   "source": [
    "## Model 2 — Principal Components Regression (PCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cbb2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pcr_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA()),\n",
    "    (\"lin\", LinearRegression())\n",
    "])\n",
    "\n",
    "# Choose k by CV over a small grid (e.g., 2..10 or up to #features)\n",
    "max_k = min(12, len(num_cols))\n",
    "grid = {\"pca__n_components\": list(range(2, max_k+1))}\n",
    "gs_pcr = GridSearchCV(pcr_pipe, grid, scoring=rmsle_scorer, cv=cv, n_jobs=-1)\n",
    "gs_pcr.fit(X[num_cols], y)\n",
    "\n",
    "best_pcr = gs_pcr.best_estimator_\n",
    "print(\"Best PCR k:\", gs_pcr.best_params_, \"CV RMSLE:\", -gs_pcr.best_score_)\n",
    "\n",
    "# Report variance explained\n",
    "scaler = StandardScaler().fit(X[num_cols])\n",
    "Xp = scaler.transform(X[num_cols])\n",
    "pca_temp = PCA(n_components=gs_pcr.best_params_[\"pca__n_components\"]).fit(Xp)\n",
    "var_expl = pca_temp.explained_variance_ratio_.sum()*100\n",
    "print(f\"PCR variance explained (k={pca_temp.n_components_}): {var_expl:.2f}%\")\n",
    "\n",
    "# CV report for PCR\n",
    "m2_mean, m2_sd = cv_rmsle(best_pcr, X[num_cols], y, cv)\n",
    "print(f\"Model 2 PCR CV RMSLE = {m2_mean:.5f} ± {m2_sd:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa1ceb2",
   "metadata": {},
   "source": [
    "### Generate Kaggle Submission — Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_pcr.fit(X[num_cols], y)\n",
    "pred2 = np.maximum(best_pcr.predict(X_test[num_cols]), 0)\n",
    "\n",
    "sub2 = sample.copy()\n",
    "sub_target = sub2.columns[1] if sub2.shape[1] == 2 else [c for c in sub2.columns if c != sub2.columns[0]][0]\n",
    "sub2[sub_target] = pred2\n",
    "sub2_path = \"submission_model2_pcr.csv\"\n",
    "sub2.to_csv(sub2_path, index=False)\n",
    "print(\"Saved:\", sub2_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe9e5d",
   "metadata": {},
   "source": [
    "## Results Summary (for one-pager paste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c74993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Model 1 (Elastic Net → subset OLS): CV RMSLE = {m1_mean:.5f} ± {m1_sd:.5f}\")\n",
    "print(f\"Model 2 (PCR): CV RMSLE = {m2_mean:.5f} ± {m2_sd:.5f}\")\n",
    "print(\"Replace with Kaggle scores after upload:\")\n",
    "print(\"Model 1 Kaggle: Private = 0.16339; Public = 0.16383\")\n",
    "print(\"Model 2 Kaggle: Private = 0.28444; Public = 0.28753\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
